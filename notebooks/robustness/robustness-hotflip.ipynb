{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "加载 Qwen模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 1024)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
              "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((1024,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((1024,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm((1024,), eps=1e-06)\n",
              "    (rotary_emb): Qwen2RotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
        "model_name = \"Qwen/Qwen1.5-0.5B-Chat\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "model.to(device).eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Qwen 是 GPT 模型，分类只能使用 1 shot 提示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt_tpl = \"For the given sentence, label the sentiment of the sentence as positive or negative. The answer should be exactly 'positive' or 'negative'.\\nsentence: {}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#情感分类\n",
        "def qwen_sentiment_predict(sentence, prompt_tpl):\n",
        "    prompt = prompt_tpl.format(sentence)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "    generated_ids = model.generate(\n",
        "        input_ids=model_inputs.input_ids,\n",
        "        attention_mask=model_inputs.attention_mask,\n",
        "        max_new_tokens=512\n",
        "    )\n",
        "    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]\n",
        "    result = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    if \"positive\" in result.lower() or \"正面\" in result:\n",
        "        return 1\n",
        "    elif \"negative\" in result.lower() or \"负面\" in result:\n",
        "        return 0\n",
        "    else:\n",
        "        return -1  # 未识别"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "使用 FlipHot方法进行尝试，HotFlip 本质是找到“最容易让模型出错”的关键词和替换词；替换词表的选择标准，就是——替换后loss增大最多的词，即最符合攻击目标的词。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_subsequence_idx(long_seq, sub_seq):\n",
        "    \"\"\"\n",
        "    返回sub_seq在long_seq中出现的起始和结束索引 (闭区间)，若不存在则返回(-1, -1)\n",
        "    \"\"\"\n",
        "    for i in range(len(long_seq) - len(sub_seq) + 1):\n",
        "        if all(long_seq[i + j] == sub_seq[j] for j in range(len(sub_seq))):\n",
        "            return i, i + len(sub_seq) - 1\n",
        "    return -1, -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def hotflip_attack_qwen(sentence, gold_label, prompt_tpl, max_trials=50, sim_fn=None):\n",
        "    # 构造prompt\n",
        "    prompt = prompt_tpl.format(sentence)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    attn_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "    # 拿到可求梯度的embedding\n",
        "    embeds = model.get_input_embeddings()(input_ids)\n",
        "    embeds = embeds.clone().detach().requires_grad_(True)\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    # 定义正负答案的token id\n",
        "    positive_token_id = tokenizer(\"positive\", add_special_tokens=False)[\"input_ids\"][0]\n",
        "    negative_token_id = tokenizer(\"negative\", add_special_tokens=False)[\"input_ids\"][0]\n",
        "\n",
        "    # 1. 前向传播，拿到最后生成token的logits（假设模型只输出一个token作为判别）\n",
        "    outputs = model(inputs_embeds=embeds, attention_mask=attn_mask)\n",
        "    logits = outputs.logits  # [1, seq_len, vocab_size]\n",
        "\n",
        "    # 找到最后一个非pad的位置（即答案要填的地方）\n",
        "    gen_pos = attn_mask.sum().item() - 1  # 上次生成的位置\n",
        "    # 针对分类目标构造loss：最大化与gold_label相反的logit，最小化gold_label对应logit\n",
        "    if gold_label == 1:\n",
        "        # 正样本，扰动目标是最大化 negative 的概率\n",
        "        loss = -F.log_softmax(logits[0, gen_pos], dim=-1)[negative_token_id]\n",
        "    else:\n",
        "        # 负样本，扰动目标是最大化 positive 的概率\n",
        "        loss = -F.log_softmax(logits[0, gen_pos], dim=-1)[positive_token_id]\n",
        "\n",
        "    loss.backward()\n",
        "    grads = embeds.grad  # [1, seq_len, emb_dim]\n",
        "    #这里加空格的原因是 promote 中 sentence 前有空格，需要和内容保存一致。因为不同的词前面有空格和没有空格索引不同\n",
        "    user_input_ids_list = tokenizer(' ' + sentence, return_tensors=\"pt\")[\"input_ids\"][0].tolist()\n",
        "    input_ids_list = inputs[\"input_ids\"][0].tolist()\n",
        "    # 取出与原句子token数量一致的范围\n",
        "    start_idx, stop_idx = find_subsequence_idx(input_ids_list, user_input_ids_list)\n",
        "\n",
        "    if start_idx == -1:\n",
        "        print(\"未在prompt中找到原始句子token序列！\")\n",
        "        raise ValueError(\"未在prompt中找到原始句子token序列！\")\n",
        "    \n",
        "    # HotFlip时只允许扰动[start_idx, stop_idx]区间\n",
        "    # 计算saliency\n",
        "    token_saliency = grads.abs().sum(dim=-1).squeeze()\n",
        "    # 非句子区强行设为-inf\n",
        "    for i in range(token_saliency.size(0)):\n",
        "        if i < start_idx or i >= stop_idx:\n",
        "            token_saliency[i] = -float(\"inf\")\n",
        "    top_idx = torch.argmax(token_saliency).item()\n",
        "\n",
        "    orig_token_text = tokenizer.decode([input_ids[0, top_idx]])\n",
        "\n",
        "    emb_matrix = model.get_input_embeddings().weight  # [vocab_size, emb_dim]\n",
        "    orig_emb = embeds[0, top_idx].detach()\n",
        "    orig_grad = grads[0, top_idx].detach()\n",
        "    delta = emb_matrix - orig_emb\n",
        "    # top-k遍历替换\n",
        "    flip_scores, indices = torch.topk(torch.matmul(delta, orig_grad), k=max_trials)\n",
        "    for idx in indices:\n",
        "        idx = idx.item()\n",
        "        if idx == input_ids[0, top_idx]:\n",
        "            continue\n",
        "        new_token_text = tokenizer.decode([idx])\n",
        "        # 如果原始token带前导空格，候选token必须也带\n",
        "        if orig_token_text.startswith(\" \") and not new_token_text.startswith(\" \"):\n",
        "            continue  # 跳过没有前空格的token\n",
        "        perturbed_ids = input_ids.clone()\n",
        "        perturbed_ids[0, top_idx] = idx\n",
        "        # 仅句子部分\n",
        "        perturbed_sentence = tokenizer.decode(perturbed_ids[0, start_idx:stop_idx+1], skip_special_tokens=True)\n",
        "        \n",
        "        # 语义相似度筛选\n",
        "        if sim_fn is not None and not sim_fn(sentence, perturbed_sentence):\n",
        "            continue\n",
        "        # 判断扰动是否导致分类翻转\n",
        "        pred = qwen_sentiment_predict(perturbed_sentence, prompt_tpl)\n",
        "        success = (pred != gold_label and pred != -1)\n",
        "        if success:\n",
        "            return perturbed_sentence, top_idx - start_idx, idx, success\n",
        "    # 未成功\n",
        "    return sentence, None, None, False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# 加载预训练的英文句嵌入模型（可选：paraphrase-MiniLM-L6-v2等）\n",
        "sbert = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "def sim_fn(sent1, sent2, threshold=0.8):\n",
        "    \"\"\"\n",
        "    计算两个句子的余弦语义相似度，若大于阈值返回True，否则False\n",
        "    \"\"\"\n",
        "    if sent1.strip() == sent2.strip():\n",
        "        return True  # 完全一致\n",
        "    emb1 = sbert.encode(sent1, convert_to_tensor=True)\n",
        "    emb2 = sbert.encode(sent2, convert_to_tensor=True)\n",
        "    sim = util.pytorch_cos_sim(emb1, emb2).item()  # 取标量\n",
        "    return sim >= threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "预测结果： 0\n",
            "扰动后句子： The film is not interesting at all.\n",
            "攻击成功？ False\n"
          ]
        }
      ],
      "source": [
        "sentence = \"The film is not interesting at all.\"\n",
        "label = 0  # 积极\n",
        "pred = qwen_sentiment_predict(sentence=sentence, prompt_tpl=prompt_tpl)\n",
        "print(\"预测结果：\", pred)\n",
        "\n",
        "perturbed_sentence, idx, new_token, success = hotflip_attack_qwen(\n",
        "    sentence, label, prompt_tpl,\n",
        "    max_trials=50,\n",
        "    sim_fn=sim_fn\n",
        ")\n",
        "print(\"扰动后句子：\", perturbed_sentence)\n",
        "print(\"攻击成功？\", success)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "def save_qwen_sst2_correct(\n",
        "    prompt_tpl,\n",
        "    save_path,\n",
        "    max_samples=None  # 可选：限制最大样本数，加速调试\n",
        "):\n",
        "    \"\"\"\n",
        "    用 Qwen 对 glue-sst2 数据做预测，保存预测正确的数据到 .parquet 文件，格式与glue-sst2一致。\n",
        "\n",
        "    Args:\n",
        "        qwen_sentiment_predict: 你的情感预测函数，入参(sentence, prompt_tpl)\n",
        "        prompt_tpl: prompt模板字符串\n",
        "        save_path: 保存文件的路径（.parquet）\n",
        "        split: SST-2数据集的子集 (default: validation)\n",
        "        max_samples: 最大样本数（调试用，None表示全部处理）\n",
        "    \"\"\"\n",
        "    # 加载数据\n",
        "    dataset = load_dataset(\"glue\", \"sst2\", split=\"validation\")\n",
        "    if max_samples:\n",
        "        dataset = dataset.select(range(max_samples))\n",
        "\n",
        "    correct_samples = []\n",
        "    for row in tqdm(dataset, desc=f\"Qwen预测SST-2-validation\"):\n",
        "        sentence = row['sentence']\n",
        "        label = row['label']\n",
        "        pred = qwen_sentiment_predict(sentence, prompt_tpl)\n",
        "        if pred == label:\n",
        "            correct_samples.append({'sentence': sentence, 'label': label})\n",
        "\n",
        "    df = pd.DataFrame(correct_samples)\n",
        "    df.to_parquet(save_path, index=False)\n",
        "    print(f\"已保存 {len(df)} 条预测正确的样本到 {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "#如果没有创建文件的目录，去掉注释\n",
        "dataPath = \"~/data/hotflip\"\n",
        "#!mkdir -p dataPath\n",
        "filePath = f\"{dataPath}/qwen_sst2_correct.parquet\"\n",
        "# save_qwen_sst2_correct(prompt_tpl, filePath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "sentence = \" although laced with humor and a few fanciful touches , the film is a refreshingly serious look at young women .\"\n",
        "pred = qwen_sentiment_predict(sentence, prompt_tpl)\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "生成扰动句子"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "def generate_hotflip_perturbed_dataset(\n",
        "    parquet_path,                   # 输入parquet文件路径\n",
        "    hotflip_attack_qwen,            # 热flip攻击函数（如前面实现）\n",
        "    prompt_tpl,                     # 分类prompt模板\n",
        "    sim_fn=None,                    # 可选，语义相似度过滤函数\n",
        "    save_path='./data/perturbed.parquet',\n",
        "    max_trials=50,\n",
        "):\n",
        "    \"\"\"\n",
        "    读取已保存的parquet分类数据，批量生成HotFlip扰动句并保存。\n",
        "    \"\"\"\n",
        "    df = pd.read_parquet(parquet_path)\n",
        "    # INSERT_YOUR_CODE\n",
        "    # df = df.head(10)\n",
        "    print(f\"加载到 {len(df)} 条数据\")\n",
        "    perturbed_samples = []\n",
        "    for row in tqdm(df.itertuples(), total=len(df), desc=\"生成HotFlip扰动句\"):\n",
        "        orig_sentence = row.sentence\n",
        "        label = row.label\n",
        "        perturbed_sentence, idx, new_token, success = hotflip_attack_qwen(\n",
        "            orig_sentence, label, prompt_tpl, max_trials=max_trials, sim_fn=sim_fn\n",
        "        )\n",
        "        if success:\n",
        "            sample = {\n",
        "                'orig_sentence': orig_sentence,\n",
        "                'label': label,\n",
        "                'sentence': perturbed_sentence,\n",
        "                }\n",
        "            perturbed_samples.append(sample)\n",
        "    out_df = pd.DataFrame(perturbed_samples)\n",
        "    out_df.to_parquet(save_path, index=False)\n",
        "    print(f\"已保存扰动数据集到 {save_path}\")\n",
        "    return out_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "加载到 751 条数据\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "生成HotFlip扰动句: 100%|██████████| 751/751 [31:49<00:00,  2.54s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "已保存扰动数据集到 ~/data/hotflip/qwen_sst2_perturbed.parquet\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>orig_sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>it 's a charming and often affecting journey .</td>\n",
              "      <td>1</td>\n",
              "      <td>it 's a � and often affecting journey .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>although laced with humor and a few fanciful t...</td>\n",
              "      <td>1</td>\n",
              "      <td>although laced with humor and a few fanciful ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the emotions are raw and will strike a nerve w...</td>\n",
              "      <td>1</td>\n",
              "      <td>the emotions are requested and will strike a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pumpkin takes an admirable look at the hypocri...</td>\n",
              "      <td>0</td>\n",
              "      <td>pumpkin takes an admirable look at the zaw of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>it 's an offbeat treat that pokes fun at the d...</td>\n",
              "      <td>1</td>\n",
              "      <td>it 's an off芝 treat that pokes fun at the dem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>in a way , the film feels like a breath of fre...</td>\n",
              "      <td>1</td>\n",
              "      <td>in a way , the film feels like a breath of fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>while it 's genuinely cool to hear characters ...</td>\n",
              "      <td>0</td>\n",
              "      <td>while it 's genuinely cool to hear characters...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>the far future may be awesome to consider , bu...</td>\n",
              "      <td>1</td>\n",
              "      <td>the far future may be awesome to consider , b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>... is an arthritic attempt at directing by ca...</td>\n",
              "      <td>0</td>\n",
              "      <td>... is an arth愉快 attempt at directing by call...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>looking aristocratic , luminous yet careworn i...</td>\n",
              "      <td>1</td>\n",
              "      <td>looking aristocratic , luminous yet careworn ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>154 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         orig_sentence  label  \\\n",
              "0      it 's a charming and often affecting journey .       1   \n",
              "1    although laced with humor and a few fanciful t...      1   \n",
              "2    the emotions are raw and will strike a nerve w...      1   \n",
              "3    pumpkin takes an admirable look at the hypocri...      0   \n",
              "4    it 's an offbeat treat that pokes fun at the d...      1   \n",
              "..                                                 ...    ...   \n",
              "149  in a way , the film feels like a breath of fre...      1   \n",
              "150  while it 's genuinely cool to hear characters ...      0   \n",
              "151  the far future may be awesome to consider , bu...      1   \n",
              "152  ... is an arthritic attempt at directing by ca...      0   \n",
              "153  looking aristocratic , luminous yet careworn i...      1   \n",
              "\n",
              "                                              sentence  \n",
              "0             it 's a � and often affecting journey .   \n",
              "1     although laced with humor and a few fanciful ...  \n",
              "2     the emotions are requested and will strike a ...  \n",
              "3     pumpkin takes an admirable look at the zaw of...  \n",
              "4     it 's an off芝 treat that pokes fun at the dem...  \n",
              "..                                                 ...  \n",
              "149   in a way , the film feels like a breath of fr...  \n",
              "150   while it 's genuinely cool to hear characters...  \n",
              "151   the far future may be awesome to consider , b...  \n",
              "152   ... is an arth愉快 attempt at directing by call...  \n",
              "153   looking aristocratic , luminous yet careworn ...  \n",
              "\n",
              "[154 rows x 3 columns]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 调用方法举例\n",
        "generate_hotflip_perturbed_dataset(\n",
        "    parquet_path=filePath,\n",
        "    hotflip_attack_qwen=hotflip_attack_qwen,\n",
        "    prompt_tpl=prompt_tpl,\n",
        "    sim_fn=sim_fn,\n",
        "    save_path='~/data/hotflip/qwen_sst2_perturbed.parquet',\n",
        "    max_trials=50,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
