ğŸ“š å¤§è¯­è¨€æ¨¡å‹è¯„æµ‹é…å¥—é¡¹ç›®ï¼ˆä¸­æ–‡ç‰ˆï¼‰

æœ¬é¡¹ç›®ä¸ºã€Šå¤§è¯­è¨€æ¨¡å‹è¯„æµ‹ã€‹ä¸€ä¹¦æä¾›å®Œæ•´çš„é…å¥—ä»£ç ã€å·¥å…·ä¸æ•°æ®é›†ç¤ºä¾‹ï¼Œå¸®åŠ©è¯»è€…æ·±å…¥ç†è§£ã€åŠ¨æ‰‹å®è·µï¼Œå¹¶æŒæ¡å¦‚ä½•è¯„æµ‹å¤§è¯­è¨€æ¨¡å‹çš„å„é¡¹èƒ½åŠ›ã€‚

â¸»

ğŸš€ é¡¹ç›®ç»“æ„ä¸å†…å®¹

æœ¬ä¹¦é…å¥—çš„ä»£ç ä»“åº“åˆ†ä¸ºä¸¤ä¸ªé¡¹ç›®ï¼š

ğŸ“Œ é¡¹ç›®ä¸€ï¼šäº¤äº’å¼æ•™å­¦ä»“åº“ï¼ˆJupyter Notebooksï¼‰

how-llm-evaluation-works
ğŸ“— å¯¹åº”ä¹¦ä¸­å„ç« èŠ‚å†…å®¹ï¼Œé€æ­¥æ¼”ç¤ºå¤§è¯­è¨€æ¨¡å‹çš„è¯„æµ‹è¿‡ç¨‹ã€‚

	â€¢	âœ… Jupyter Notebookå½¢å¼ï¼Œæ–¹ä¾¿æœ¬åœ°å’ŒGoogle Colabç›´æ¥è¿è¡Œã€‚
	â€¢	âœ… æ¯ä¸€ç« å†…å®¹éƒ½ç‹¬ç«‹æˆNotebookï¼Œæä¾›è¯¦ç»†ä»£ç æ³¨é‡Šå’Œè¾“å‡ºæ¼”ç¤ºã€‚
	â€¢	âœ… è¦†ç›–é²æ£’æ€§ã€è¯­ä¹‰ç›¸ä¼¼åº¦ã€è¾“å‡ºä¸€è‡´æ€§ã€å®‰å…¨æ€§ã€å…¬å¹³æ€§ç­‰æ ¸å¿ƒè¯„æµ‹ç»´åº¦ã€‚

ç›®å½•ç¤ºä¾‹ï¼š

how-llm-evaluation-works/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ notebooks/
    â”œâ”€â”€ 01_robustness_evaluation.ipynb
    â”œâ”€â”€ 02_semantic_similarity.ipynb
    â”œâ”€â”€ 03_output_consistency.ipynb
    â””â”€â”€ 04_security_fairness.ipynb

ğŸ“Œ é¡¹ç›®äºŒï¼šæ ¸å¿ƒè¯„æµ‹å·¥å…·åº“ï¼ˆPython Packageï¼‰

llm-eval-kit
ğŸ› ï¸ ç‹¬ç«‹çš„å¯å¤ç”¨è¯„æµ‹æ¨¡å—ï¼Œç”¨äºå¿«é€Ÿå®ç°å’Œæ‰©å±•å¤§è¯­è¨€æ¨¡å‹è¯„æµ‹ä»»åŠ¡ã€‚

	â€¢	âœ… å°è£…æ–‡æœ¬æ‰°åŠ¨ã€è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—ã€è¯„æµ‹æŒ‡æ ‡å·¥å…·ã€‚
	â€¢	âœ… æ”¯æŒä¸»æµå¤§è¯­è¨€æ¨¡å‹çš„è¯„æµ‹ï¼ˆå¦‚GPTç³»åˆ—ã€LLaMAç³»åˆ—ã€Qwenç­‰ï¼‰ã€‚
	â€¢	âœ… æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºé›†æˆåˆ°å…¶ä»–è¯„æµ‹æˆ–ç ”ç©¶é¡¹ç›®ã€‚

ç»“æ„ç¤ºä¾‹ï¼š

llm-eval-kit/
â”œâ”€â”€ README.md
â”œâ”€â”€ setup.py
â”œâ”€â”€ llm_eval_kit/
â”‚   â”œâ”€â”€ perturbation.py
â”‚   â”œâ”€â”€ semantic_similarity.py
â”‚   â”œâ”€â”€ evaluator.py
â”‚   â””â”€â”€ models.py
â””â”€â”€ examples/
    â””â”€â”€ quickstart.py


â¸»

âš¡ å¿«é€Ÿä¸Šæ‰‹æŒ‡å—

ğŸ–¥ï¸ æ•™å­¦ä»£ç åº“å¿«é€Ÿå¯åŠ¨ï¼š

# å…‹éš†æ•™å­¦ä»£ç ä»“åº“
git clone https://github.com/fanndu/how-llm-evaluation-works
cd how-llm-evaluation-works
pip install -r requirements.txt

# ä½¿ç”¨ Jupyter Lab å¯åŠ¨
jupyter lab

æˆ–ä½¿ç”¨ Google Colab åœ¨çº¿è¿è¡Œã€‚

ğŸ“¦ å·¥å…·åº“å®‰è£…ä¸ä½¿ç”¨ï¼š

# å…‹éš†æ ¸å¿ƒè¯„æµ‹å·¥å…·åº“
git clone https://github.com/fanndu/llm-eval-kit
cd llm-eval-kit

# å®‰è£…ä¾èµ–
pip install -e .

# è¿è¡Œç¤ºä¾‹
python examples/quickstart.py


â¸»

ğŸ› ï¸ ä¾èµ–ç¯å¢ƒ
	â€¢	Python >= 3.10
	â€¢	PyTorch
	â€¢	HuggingFace Transformers
	â€¢	sentence-transformers
	â€¢	numpy, pandas

ï¼ˆè¯¦è§æ¯ä¸ªä»“åº“ä¸‹çš„requirements.txtï¼‰

â¸»

ğŸ“œ è®¸å¯è¯ï¼ˆLicenseï¼‰

æœ¬ä¹¦é…å¥—é¡¹ç›®ä½¿ç”¨å¦‚ä¸‹è®¸å¯è¯ï¼š
	â€¢	æ•™å­¦ä»£ç ä»“åº“ï¼šMIT License
	â€¢	æ ¸å¿ƒå·¥å…·åº“ï¼šApache License 2.0

â¸»

